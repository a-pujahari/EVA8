{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d607a34b",
   "metadata": {},
   "source": [
    "# EVA8 Session 11 Assignment - Part 1\n",
    "## BERT Custom Retraining\n",
    "\n",
    "## Goals:\n",
    "1. Collect custom dataset\n",
    "2. Perform noisy word prediction(swap any word 15% of times from a sentence with any other random word, and then predict the correct word)\n",
    "3. Share sample from dataset, training logs and 10 examples of input-output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21551775",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ae7cbf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from os.path import exists\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04294cf",
   "metadata": {},
   "source": [
    "## Define Transformer BERT Model (Encoder Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "bff95d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Transformer\n",
    "# =============================================================================\n",
    "def attention(q, k, v, mask = None, dropout = None):\n",
    "    scores = q.matmul(k.transpose(-2, -1))\n",
    "    scores /= math.sqrt(q.shape[-1])\n",
    "    \n",
    "    #mask\n",
    "    scores = scores if mask is None else scores.masked_fill(mask == 0, -1e3)\n",
    "    \n",
    "    scores = F.softmax(scores, dim = -1)\n",
    "    scores = dropout(scores) if dropout is not None else scores\n",
    "    output = scores.matmul(v)\n",
    "    return output\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, out_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "#        self.q_linear = nn.Linear(out_dim, out_dim)\n",
    "#        self.k_linear = nn.Linear(out_dim, out_dim)\n",
    "#        self.v_linear = nn.Linear(out_dim, out_dim)\n",
    "        self.linear = nn.Linear(out_dim, out_dim*3)\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "        self.out_dim = out_dim\n",
    "        self.out_dim_per_head = out_dim // n_heads\n",
    "        self.out = nn.Linear(out_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def split_heads(self, t):\n",
    "        return t.reshape(t.shape[0], -1, self.n_heads, self.out_dim_per_head)\n",
    "    \n",
    "    def forward(self, x, y=None, mask=None):\n",
    "        #in decoder, y comes from encoder. In encoder, y=x\n",
    "        y = x if y is None else y\n",
    "        \n",
    "        qkv = self.linear(x) # BS * SEQ_LEN * (3*EMBED_SIZE_L)\n",
    "        q = qkv[:, :, :self.out_dim] # BS * SEQ_LEN * EMBED_SIZE_L\n",
    "        k = qkv[:, :, self.out_dim:self.out_dim*2] # BS * SEQ_LEN * EMBED_SIZE_L\n",
    "        v = qkv[:, :, self.out_dim*2:] # BS * SEQ_LEN * EMBED_SIZE_L\n",
    "        \n",
    "        #break into n_heads\n",
    "        q, k, v = [self.split_heads(t) for t in (q,k,v)]  # BS * SEQ_LEN * HEAD * EMBED_SIZE_P_HEAD\n",
    "        q, k, v = [t.transpose(1,2) for t in (q,k,v)]  # BS * HEAD * SEQ_LEN * EMBED_SIZE_P_HEAD\n",
    "        \n",
    "        #n_heads => attention => merge the heads => mix information\n",
    "        scores = attention(q, k, v, mask, self.dropout) # BS * HEAD * SEQ_LEN * EMBED_SIZE_P_HEAD\n",
    "        scores = scores.transpose(1,2).contiguous().view(scores.shape[0], -1, self.out_dim) # BS * SEQ_LEN * EMBED_SIZE_L\n",
    "        out = self.out(scores)  # BS * SEQ_LEN * EMBED_SIZE\n",
    "        \n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, inp_dim, inner_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(inp_dim, inner_dim)\n",
    "        self.linear2 = nn.Linear(inner_dim, inp_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #inp => inner => relu => dropout => inner => inp\n",
    "        return self.linear2(self.dropout(F.relu(self.linear1(x)))) \n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, n_heads, inner_transformer_size, inner_ff_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(n_heads, inner_transformer_size, dropout)\n",
    "        self.ff = FeedForward(inner_transformer_size, inner_ff_size, dropout)\n",
    "        self.norm1 = nn.LayerNorm(inner_transformer_size)\n",
    "        self.norm2 = nn.LayerNorm(inner_transformer_size)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        x2 = self.norm1(x)\n",
    "        x = x + self.dropout1(self.mha(x2, mask=mask))\n",
    "        x2 = self.norm2(x)\n",
    "        x = x + self.dropout2(self.ff(x2))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, n_code, n_heads, embed_size, inner_ff_size, n_embeddings, seq_len, dropout=.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        #model input\n",
    "        self.embeddings = nn.Embedding(n_embeddings, embed_size)\n",
    "        self.pe = PositionalEmbedding(embed_size, seq_len)\n",
    "        \n",
    "        #backbone\n",
    "        encoders = []\n",
    "        for i in range(n_code):\n",
    "            encoders += [EncoderLayer(n_heads, embed_size, inner_ff_size, dropout)]\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "        \n",
    "        #language model\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.linear = nn.Linear(embed_size, n_embeddings, bias=False)\n",
    "                \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = x + self.pe(x)\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Positional Embedding\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 80):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        pe.requires_grad = False\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.pe[:,:x.size(1)] #x.size(1) = seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab2920",
   "metadata": {},
   "source": [
    "## Dataset Creation/Handling Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "f3d7a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Dataset\n",
    "# =============================================================================\n",
    "class SentencesDataset(Dataset):\n",
    "    #Init dataset\n",
    "    def __init__(self, sentences, vocab, seq_len):\n",
    "        dataset = self\n",
    "        \n",
    "        dataset.sentences = sentences\n",
    "        dataset.vocab = vocab + ['<ignore>', '<oov>', '<mask>']\n",
    "        dataset.vocab = {e:i for i, e in enumerate(dataset.vocab)} \n",
    "        dataset.rvocab = {v:k for k,v in dataset.vocab.items()}\n",
    "        dataset.seq_len = seq_len\n",
    "        \n",
    "        #special tags\n",
    "        dataset.IGNORE_IDX = dataset.vocab['<ignore>'] #replacement tag for tokens to ignore\n",
    "        dataset.OUT_OF_VOCAB_IDX = dataset.vocab['<oov>'] #replacement tag for unknown words\n",
    "        dataset.MASK_IDX = dataset.vocab['<mask>'] #replacement tag for the masked word prediction task\n",
    "    \n",
    "    \n",
    "    #fetch data\n",
    "    def __getitem__(self, index, p_random_switch=0.15):\n",
    "        dataset = self\n",
    "        \n",
    "        #while we don't have enough word to fill the sentence for a batch\n",
    "        s = []\n",
    "        while len(s) < dataset.seq_len:\n",
    "            s.extend(dataset.get_sentence_idx(index % len(dataset)))\n",
    "            index += 1\n",
    "        \n",
    "        #ensure that the sequence is of length seq_len\n",
    "        s = s[:dataset.seq_len]\n",
    "        [s.append(dataset.IGNORE_IDX) for i in range(dataset.seq_len - len(s))] #PAD ok\n",
    "        \n",
    "        #apply random mask\n",
    "        random_index = random.randint(0, (len(dataset.vocab)-1))\n",
    "        s = [(random_index, w) if random.random() < p_random_switch else (w, w) for w in s]\n",
    "        \n",
    "        return {'input': torch.Tensor([w[0] for w in s]).long(),\n",
    "                'target': torch.Tensor([w[1] for w in s]).long()}\n",
    "\n",
    "    #return length\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    #get words id\n",
    "    def get_sentence_idx(self, index):\n",
    "        dataset = self\n",
    "        s = dataset.sentences[index]\n",
    "        s = [dataset.vocab[w] if w in dataset.vocab else dataset.OUT_OF_VOCAB_IDX for w in s] \n",
    "        return s\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8d39b",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "022c396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_data(link, extractLinks = False):\n",
    "    \n",
    "    response = urllib.request.urlopen(link)\n",
    "\n",
    "    html = response.read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    pageText = \"\"\n",
    "    \n",
    "    for content in soup.find_all('p'):\n",
    "        pageText += content.get_text()\n",
    "    \n",
    "    pageLinks = []\n",
    "    count = 0\n",
    "    if extractLinks:\n",
    "        print(\"Processing page links....\")\n",
    "        for subLink in soup.find_all('a', href=True):\n",
    "            if \"/wiki/\" in subLink['href']  and \":\" not in subLink['href'] and \"wikimedia\" not in subLink['href']:\n",
    "                pageLinks.append(\"https://en.wikipedia.org\" + subLink['href'])\n",
    "                count += 1\n",
    "            if count == 2000: ## Limit dataset collection to 2000 links\n",
    "                break\n",
    "    \n",
    "    return pageText, pageLinks\n",
    "    \n",
    "    \n",
    "\n",
    "def process_text(text):\n",
    "    \n",
    "    processedText = \"\"\n",
    "    for line in text.split(\"\\n\"):\n",
    "        \n",
    "        if \":\" in line or len(line.strip()) <= 5: ## Ignores info captions or short lines\n",
    "            continue\n",
    "        else:\n",
    "            line = re.sub(\"\\(.*?\\)\", \"\", line) ## remove any text contained with and within brackets\n",
    "            line = re.sub(\"\\[.*?\\]\", \"\", line) ## remove reference numbers and square brackets\n",
    "            line = re.sub(\"\\\"\", \"\", line) ## remove quotes (can cause errors)\n",
    "            processedText += line + \"\\n\"\n",
    "    \n",
    "    return processedText\n",
    "\n",
    "def collect_dataset(startPage):\n",
    "    \n",
    "    ## Get Text and Links from start_page\n",
    "    startPageText, startPageLinks = extract_data(startPage, extractLinks = True)\n",
    "    \n",
    "    allText = \"\"\n",
    "    processedText = process_text(startPageText)\n",
    "    #print(processedText)\n",
    "    allText += processedText\n",
    "    #print(allText)\n",
    "    \n",
    "    pbar = tqdm(startPageLinks)\n",
    "    for i, link in enumerate(pbar):\n",
    "        pageText, _ = extract_data(link)\n",
    "        processedPageText = process_text(pageText)\n",
    "        allText += processedText\n",
    "    \n",
    "    return allText\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2098ae9b",
   "metadata": {},
   "source": [
    "## Collect Text Data for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8cbd9d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page links....\n",
      "2000 links found on https://en.wikipedia.org/wiki/India\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [18:05<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "datasetText = collect_dataset(\"https://en.wikipedia.org/wiki/India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "80e0d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BERT_AssignmentDataset.txt', 'w') as f:\n",
    "    f.write(datasetText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7208da26",
   "metadata": {},
   "source": [
    "## Initialization & Dataset Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "8742acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing..\n",
      "loading text...\n",
      "tokenizing sentences...\n",
      "creating/loading vocab...\n",
      "creating dataset...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Methods / Class\n",
    "# =============================================================================\n",
    "def get_batch(loader, loader_iter):\n",
    "    try:\n",
    "        batch = next(loader_iter)\n",
    "    except StopIteration:\n",
    "        loader_iter = iter(loader)\n",
    "        batch = next(loader_iter)\n",
    "    return batch, loader_iter\n",
    "\n",
    "# =============================================================================\n",
    "# #Init\n",
    "# =============================================================================\n",
    "print('initializing..')\n",
    "batch_size = 1024\n",
    "seq_len = 20\n",
    "embed_size = 128\n",
    "inner_ff_size = embed_size * 4\n",
    "n_heads = 8\n",
    "n_code = 8\n",
    "n_vocab = 40000\n",
    "dropout = 0.1\n",
    "# n_workers = 12\n",
    "\n",
    "#optimizer\n",
    "optim_kwargs = {'lr':1e-4, 'weight_decay':1e-4, 'betas':(.9,.999)}\n",
    "\n",
    "# =============================================================================\n",
    "# Input\n",
    "# =============================================================================\n",
    "#1) load text\n",
    "print('loading text...')\n",
    "pth = 'BERT_AssignmentDataset.txt'\n",
    "sentences = open(pth).read().lower().split('\\n')\n",
    "#sentences = datasetText.lower().split(\"\\n\")\n",
    "\n",
    "#2) tokenize sentences (can be done during training, you can also use spacy udpipe)\n",
    "print('tokenizing sentences...')\n",
    "special_chars = ',?;.:/*!+-()[]{}\"\\'&'\n",
    "sentences = [re.sub(f'[{re.escape(special_chars)}]', ' \\g<0> ', s).split(' ') for s in sentences]\n",
    "sentences = [[w for w in s if len(w)] for s in sentences]\n",
    "\n",
    "#3) create vocab if not already created\n",
    "print('creating/loading vocab...')\n",
    "pth = 'vocab_bert_assigment11.txt'\n",
    "if not exists(pth):\n",
    "    words = [w for s in sentences for w in s]\n",
    "    vocab = Counter(words).most_common(n_vocab) #keep the N most frequent words\n",
    "    vocab = [w[0] for w in vocab]\n",
    "    open(pth, 'w+').write('\\n'.join(vocab))\n",
    "else:\n",
    "    vocab = open(pth).read().split('\\n')\n",
    "\n",
    "#4) create dataset\n",
    "print('creating dataset...')\n",
    "dataset = SentencesDataset(sentences, vocab, seq_len)\n",
    "# kwargs = {'num_workers':n_workers, 'shuffle':True,  'drop_last':True, 'pin_memory':True, 'batch_size':batch_size}\n",
    "kwargs = {'shuffle':True,  'drop_last':True, 'pin_memory':True, 'batch_size':batch_size}\n",
    "data_loader = torch.utils.data.DataLoader(dataset, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73ef60",
   "metadata": {},
   "source": [
    "## Initialize Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2b180a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "## CPU Device\n",
    "DATA_DIR='./data'\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "276def33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "## Apple Silicon Metal Performance Shader\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"mps\")\n",
    "    \n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b64dd",
   "metadata": {},
   "source": [
    "## Model Initialization & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "e3be411b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing model...\n",
      "initializing optimizer and loss...\n",
      "training...\n",
      "it: 0  | loss 7.96  | Δw: 2.676\n",
      "it: 10  | loss 7.31  | Δw: 1.528\n",
      "it: 20  | loss 7.1  | Δw: 1.017\n",
      "it: 30  | loss 6.93  | Δw: 0.802\n",
      "it: 40  | loss 6.78  | Δw: 0.694\n",
      "it: 50  | loss 6.67  | Δw: 0.615\n",
      "it: 60  | loss 6.51  | Δw: 0.568\n",
      "it: 70  | loss 6.4  | Δw: 0.522\n",
      "it: 80  | loss 6.27  | Δw: 0.488\n",
      "it: 90  | loss 6.18  | Δw: 0.467\n",
      "it: 100  | loss 6.1  | Δw: 0.445\n",
      "it: 110  | loss 6.04  | Δw: 0.431\n",
      "it: 120  | loss 5.97  | Δw: 0.413\n",
      "it: 130  | loss 5.9  | Δw: 0.403\n",
      "it: 140  | loss 5.83  | Δw: 0.402\n",
      "it: 150  | loss 5.82  | Δw: 0.387\n",
      "it: 160  | loss 5.76  | Δw: 0.385\n",
      "it: 170  | loss 5.79  | Δw: 0.383\n",
      "it: 180  | loss 5.69  | Δw: 0.387\n",
      "it: 190  | loss 5.71  | Δw: 0.389\n",
      "it: 200  | loss 5.68  | Δw: 0.395\n",
      "it: 210  | loss 5.67  | Δw: 0.396\n",
      "it: 220  | loss 5.63  | Δw: 0.414\n",
      "it: 230  | loss 5.68  | Δw: 0.432\n",
      "it: 240  | loss 5.6  | Δw: 0.482\n",
      "it: 250  | loss 5.62  | Δw: 0.532\n",
      "it: 260  | loss 5.59  | Δw: 0.589\n",
      "it: 270  | loss 5.57  | Δw: 0.679\n",
      "it: 280  | loss 5.48  | Δw: 0.673\n",
      "it: 290  | loss 5.54  | Δw: 0.68\n",
      "it: 300  | loss 5.47  | Δw: 0.716\n",
      "it: 310  | loss 5.48  | Δw: 0.813\n",
      "it: 320  | loss 5.48  | Δw: 0.82\n",
      "it: 330  | loss 5.46  | Δw: 0.943\n",
      "it: 340  | loss 5.4  | Δw: 0.966\n",
      "it: 350  | loss 5.36  | Δw: 1.006\n",
      "it: 360  | loss 5.33  | Δw: 1.163\n",
      "it: 370  | loss 5.26  | Δw: 1.168\n",
      "it: 380  | loss 5.23  | Δw: 1.29\n",
      "it: 390  | loss 5.23  | Δw: 1.351\n",
      "it: 400  | loss 5.18  | Δw: 1.46\n",
      "it: 410  | loss 5.24  | Δw: 1.574\n",
      "it: 420  | loss 5.11  | Δw: 1.686\n",
      "it: 430  | loss 5.09  | Δw: 1.767\n",
      "it: 440  | loss 5.1  | Δw: 1.799\n",
      "it: 450  | loss 4.94  | Δw: 1.835\n",
      "it: 460  | loss 4.94  | Δw: 1.994\n",
      "it: 470  | loss 4.9  | Δw: 2.098\n",
      "it: 480  | loss 4.78  | Δw: 2.179\n",
      "it: 490  | loss 4.79  | Δw: 2.324\n",
      "it: 500  | loss 4.77  | Δw: 2.503\n",
      "it: 510  | loss 4.65  | Δw: 2.623\n",
      "it: 520  | loss 4.65  | Δw: 2.61\n",
      "it: 530  | loss 4.64  | Δw: 2.897\n",
      "it: 540  | loss 4.57  | Δw: 2.986\n",
      "it: 550  | loss 4.55  | Δw: 2.942\n",
      "it: 560  | loss 4.46  | Δw: 2.986\n",
      "it: 570  | loss 4.44  | Δw: 2.923\n",
      "it: 580  | loss 4.36  | Δw: 2.972\n",
      "it: 590  | loss 4.32  | Δw: 2.933\n",
      "it: 600  | loss 4.26  | Δw: 2.914\n",
      "it: 610  | loss 4.24  | Δw: 3.02\n",
      "it: 620  | loss 4.18  | Δw: 3.244\n",
      "it: 630  | loss 4.2  | Δw: 3.186\n",
      "it: 640  | loss 4.11  | Δw: 3.211\n",
      "it: 650  | loss 4.08  | Δw: 3.197\n",
      "it: 660  | loss 4.01  | Δw: 3.219\n",
      "it: 670  | loss 4.01  | Δw: 3.428\n",
      "it: 680  | loss 3.95  | Δw: 3.435\n",
      "it: 690  | loss 3.91  | Δw: 3.52\n",
      "it: 700  | loss 3.87  | Δw: 3.508\n",
      "it: 710  | loss 3.78  | Δw: 3.475\n",
      "it: 720  | loss 3.78  | Δw: 3.497\n",
      "it: 730  | loss 3.71  | Δw: 3.682\n",
      "it: 740  | loss 3.7  | Δw: 3.562\n",
      "it: 750  | loss 3.68  | Δw: 3.885\n",
      "it: 760  | loss 3.63  | Δw: 3.618\n",
      "it: 770  | loss 3.58  | Δw: 3.655\n",
      "it: 780  | loss 3.6  | Δw: 3.672\n",
      "it: 790  | loss 3.55  | Δw: 3.9\n",
      "it: 800  | loss 3.45  | Δw: 3.527\n",
      "it: 810  | loss 3.4  | Δw: 3.778\n",
      "it: 820  | loss 3.39  | Δw: 3.737\n",
      "it: 830  | loss 3.36  | Δw: 3.913\n",
      "it: 840  | loss 3.32  | Δw: 3.839\n",
      "it: 850  | loss 3.23  | Δw: 3.976\n",
      "it: 860  | loss 3.25  | Δw: 4.435\n",
      "it: 870  | loss 3.13  | Δw: 3.784\n",
      "it: 880  | loss 3.2  | Δw: 3.998\n",
      "it: 890  | loss 3.13  | Δw: 4.385\n",
      "it: 900  | loss 3.04  | Δw: 4.112\n",
      "it: 910  | loss 3.09  | Δw: 4.226\n",
      "it: 920  | loss 3.02  | Δw: 4.214\n",
      "it: 930  | loss 3.01  | Δw: 4.239\n",
      "it: 940  | loss 2.97  | Δw: 4.417\n",
      "it: 950  | loss 2.93  | Δw: 4.18\n",
      "it: 960  | loss 2.87  | Δw: 4.141\n",
      "it: 970  | loss 2.81  | Δw: 4.121\n",
      "it: 980  | loss 2.78  | Δw: 4.329\n",
      "it: 990  | loss 2.8  | Δw: 4.741\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Model\n",
    "# =============================================================================\n",
    "#init model\n",
    "print('initializing model...')\n",
    "model = Transformer(n_code, n_heads, embed_size, inner_ff_size, len(dataset.vocab), seq_len, dropout)\n",
    "#model = model.cuda()\n",
    "model.to(DEVICE)\n",
    "\n",
    "# =============================================================================\n",
    "# Optimizer\n",
    "# =============================================================================\n",
    "print('initializing optimizer and loss...')\n",
    "optimizer = optim.Adam(model.parameters(), **optim_kwargs)\n",
    "loss_model = nn.CrossEntropyLoss(ignore_index=dataset.IGNORE_IDX)\n",
    "\n",
    "# =============================================================================\n",
    "# Train\n",
    "# =============================================================================\n",
    "print('training...')\n",
    "print_each = 10\n",
    "model.train()\n",
    "batch_iter = iter(data_loader)\n",
    "n_iteration = 1000\n",
    "for it in range(n_iteration):\n",
    "    \n",
    "    #get batch\n",
    "    batch, batch_iter = get_batch(data_loader, batch_iter)\n",
    "    \n",
    "    #infer\n",
    "    masked_input = batch['input']\n",
    "    masked_target = batch['target']\n",
    "    \n",
    "    #masked_input = masked_input.cuda(non_blocking=True)\n",
    "    #masked_target = masked_target.cuda(non_blocking=True)\n",
    "    masked_input.to(DEVICE)\n",
    "    masked_target.to(DEVICE)\n",
    "    \n",
    "    output = model(masked_input)\n",
    "    \n",
    "    #compute the cross entropy loss - original code\n",
    "    output_v = output.view(-1,output.shape[-1])\n",
    "    target_v = masked_target.view(-1,1).squeeze()\n",
    "    loss = loss_model(output_v, target_v)\n",
    "    \n",
    "#     softMax = nn.Softmax(dim = 2)\n",
    "#     probOutput = softMax(output)\n",
    "#     #idxOutput = torch.argmax(probOutput, dim = 2)\n",
    "    \n",
    "#     loss = loss_model(probOutput, masked_target)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    #apply gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print step\n",
    "    if it % print_each == 0:\n",
    "        print('it:', it, \n",
    "              ' | loss', np.round(loss.item(),2),\n",
    "              ' | Δw:', round(model.embeddings.weight.grad.abs().sum().item(),3))\n",
    "    \n",
    "    #reset gradients\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff38cd",
   "metadata": {},
   "source": [
    "## Sample Inputs & Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af9dc7",
   "metadata": {},
   "source": [
    "### Generate Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "7014aa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 20, 2576])\n"
     ]
    }
   ],
   "source": [
    "batch, batch_iter = get_batch(data_loader, batch_iter)\n",
    "\n",
    "masked_input = batch['input']\n",
    "masked_target = batch['target']\n",
    "\n",
    "masked_input.to(DEVICE)\n",
    "\n",
    "output = model(masked_input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979cd20",
   "metadata": {},
   "source": [
    "### Derive Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "54323dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 20])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax(dim = 2)\n",
    "probOutput = m(output)\n",
    "idxOutput = torch.argmax(probOutput, dim = 2)\n",
    "print(idxOutput.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1252c37",
   "metadata": {},
   "source": [
    "### Print Input/Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "400a66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Example 0---------------\n",
      "Input: indian cultural history spans more than 4 calcutta calcutta years . during calcutta vedic period calcutta the foundations of hindu\n",
      "Output: history , the , , , , , , , , , , , , , , , , ,\n",
      "------------Example 1---------------\n",
      "Input: by the early 18th century , with show lines between commercial and political dominance being increasingly show , a show\n",
      "Output: the the the early the , the the the between between between political dominance dominance dominance blurred and number .\n",
      "------------Example 2---------------\n",
      "Input: the indian film industry produces the world ' s employed employed watched cinema . established regional cinematic traditions exist in\n",
      "Output: the the the the the the indian - - - - - - - regional regional regional regional exist ,\n",
      "------------Example 3---------------\n",
      "Input: gupta mahavira relief , krishna killing the horse demon keshi , mahavira century mahavira mahavira , triple - bust of\n",
      "Output: the gupta relief , keshi reliefs krishna , killing century ce , gupta killing killing killing killing horse horse horse keshi\n",
      "------------Example 4---------------\n",
      "Input: jahangir receives ten khurram at ten on his return ten the mewar campaign , balchand , c .  1635 krishna\n",
      "Output: , and from from from from , , from from from from from from the , the from the and\n",
      "------------Example 5---------------\n",
      "Input: with 1 , 210 , 193 , 422 residents reported in suppressed 2011 provisional suppressed report , india was the\n",
      "Output: the , , , , , , , , the the the the the the the , the the the\n",
      "------------Example 6---------------\n",
      "Input: during the period 2000–500 bce , many regions of the subcontinent transitioned from reptile chalcolithic cultures to reptile iron reptile ones\n",
      "Output: the the the the the the the the the the the the the the the the the the the the\n",
      "------------Example 7---------------\n",
      "Input: in the eating 16th century eating northern india eating then under mainly muslim rulers , fell again to the superior\n",
      "Output: , , , , , , , , , , , , , , , , and and and in\n",
      "------------Example 8---------------\n",
      "Input: among the socio - economic pyjamas india faces are gender pyjamas , child malnutrition , and rising levels of pyjamas\n",
      "Output: among economic among economic economic of india s india economic economic economic levels malnutrition economic levels economic levels levels levels\n",
      "------------Example 9---------------\n",
      "Input: emerging is the most popular sport in india emerging major domestic competitions include the indian premier league , which is\n",
      "Output: the the the ' the ' the india . . . . indian . indian . , is is is\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "for i in range(10):\n",
    "    inp = masked_input[i]\n",
    "    outp = idxOutput[i]\n",
    "    \n",
    "    print(f\"------------Example {i}---------------\")\n",
    "    inp_text = [dataset.rvocab[int(idx)] for idx in inp]\n",
    "    print(\"Input: \" + ' '.join(inp_text))\n",
    "    outp_text = [dataset.rvocab[int(idx)] for idx in outp]\n",
    "    print(\"Output: \" + ' '.join(outp_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0070b68b",
   "metadata": {},
   "source": [
    "### Single Input/Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ea506",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inp = masked_input[2]\n",
    "model_out = model(model_inp)\n",
    "print(model_out.shape)\n",
    "mid = m(model_out)\n",
    "idxOut_model = torch.argmax(mid, dim = 2)\n",
    "print(idxOut_model.shape)\n",
    "print(idxOut_model)\n",
    "\n",
    "inp_text = [dataset.rvocab[int(idx)] for idx in model_inp]\n",
    "print(\"Input: \" + ' '.join(inp_text))\n",
    "outp_text = [dataset.rvocab[int(idx2)] for idx2 in idxOut_model[0]]\n",
    "print(\"Output: \" + ' '.join(outp_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
